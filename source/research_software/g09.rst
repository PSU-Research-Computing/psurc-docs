..  g09.rst

****************
Gaussian ``g09``
****************

.. contents:: Topics

The Gaussian software is installed on linux clusters and is available for use if you are authorized to use the available license.  You must be added to the ``gaussian`` unix group in order to run ``g09`` which should be specifically requested when requesting a research account.

Setting up ``g09``

``g09`` requires some simple modifications to your user environment.  Add the following to to your ``~/.bashrc`` file::

  g09root="/share/apps"
  GAUSS_SCRDIR=/scratch/$USER/gaussian_scratch
  export g09root GAUSS_SCRDIR
  source $g09root/g09/bsd/g09.profile

The ``$GAUSS_SCRDIR`` env variable is used as the Gaussian scratch folder.  For now, leave this in your home directory and keep an eye on its size and clean up old files.

Testing Gaussian
================

.. warning:: Guassian will not run on the ``gravel.rc.pdx.edu`` cluster due to the lack of the SSE4_2 CPU instruction set.

You can test to make sure ``g09`` is working properly and your environment is set up correctly by setting up a simple ``g09`` test and then writing a schelulings script to submit the job to ``slurm``, the cluster scheduler.  The following is a simple test:

`Download g09-test.gjf <https://raw.githubusercontent.com/PSU-OIT-ARC/arc-docs/master/examples/g09/g09-test.gjf>`_

.. literalinclude:: /examples/g09/g09-test.gjf

This test file will run a single ``g09`` job using 8 threads and 4Gb of memory.

Next set up a simple ``slurm`` script to schedule your your ``g09`` job.  Set up a simple bash script with some special directives in the header to do this:

`Download g09-slurm.sh <https://raw.githubusercontent.com/PSU-OIT-ARC/arc-docs/master/examples/g09/g09-slurm.sh>`_

.. literalinclude:: /examples/g09/g09-slurm.sh

To enqueue the job run::

  sbatch g09-slurm.sh

Now check the queue to see if your job has been accepted::

  squeue

We can keep an eye on activity using::

  sinfo

or by visiting the `ganglia monitoring tool <http://gravel.rc.pdx.edu>`_.

For a more extensive test try the following ``g09`` file which will fail on servers without the correct CPU instutions required by gaussian:

`Download l2-PtCl-td.gjf <https://raw.githubusercontent.com/PSU-OIT-ARC/arc-docs/master/examples/g09/l2-PtCl-td.gjf>`_

.. literalinclude:: /examples/g09/l2-PtCl-td.gjf

Try editing or copying the ``g09-slurm.sh`` to point to the ``l2-PtCl-td.gjf`` file and launch a second job on the scheduler.

Parallelization With Linda
==========================

Gaussian ``g09`` jobs can be run in parallel across multiple nodes which may increase performance and decrease runtime of jobs if done correctly.  Documentation is spotty, but here is a sample to help you started.  More information can be found in the :ref:`dynamic hostfile` example.

A few more notes from the developers:

- "%NProcs=" (short for "%NProcShared") in the input file requests the number of cores (processors) to use via shared-memory parallelization (number per Linda worker)
- It is also possible to pass the number as an environment variable e.g. "GAUSS_PDEF=16" for 16 shared-memory cores.
- "%NProcShared=" in the input takes precedence over "GAUSS_PDEF", so one could override the latter by setting "%NProcShared" in the input file.

`Download g09-slurm.sh <https://raw.githubusercontent.com/PSU-OIT-ARC/arc-docs/master/examples/g09/linda.sh>`_

.. literalinclude:: /examples/g09/linda.sh

